{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:46:28.33673Z",
     "iopub.status.busy": "2024-06-12T22:46:28.336116Z",
     "iopub.status.idle": "2024-06-12T22:46:28.362215Z",
     "shell.execute_reply": "2024-06-12T22:46:28.360533Z",
     "shell.execute_reply.started": "2024-06-12T22:46:28.336687Z"
    },
    "id": "Z0F-PKuLyumq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:46:28.670898Z",
     "iopub.status.busy": "2024-06-12T22:46:28.670374Z",
     "iopub.status.idle": "2024-06-12T22:46:28.696562Z",
     "shell.execute_reply": "2024-06-12T22:46:28.695072Z",
     "shell.execute_reply.started": "2024-06-12T22:46:28.670858Z"
    },
    "id": "4aet9rwWyumq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tqdm\n",
    "import itertools\n",
    "import inspect\n",
    "from functools import partial\n",
    "import random\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:51:59.986335Z",
     "iopub.status.busy": "2024-06-12T22:51:59.985894Z",
     "iopub.status.idle": "2024-06-12T22:52:00.019575Z",
     "shell.execute_reply": "2024-06-12T22:52:00.018007Z",
     "shell.execute_reply.started": "2024-06-12T22:51:59.986296Z"
    },
    "id": "0SfC1YZbyumr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from load_data import load_tasks, get_functions\n",
    "from arc.load_data import load_tasks, get_functions\n",
    "\n",
    "def plot_task(task):\n",
    "    \"\"\" plots a task \"\"\"\n",
    "    examples = task['train']\n",
    "    n_examples = len(examples)\n",
    "    cmap = ListedColormap([\n",
    "        '#000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n",
    "        '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'\n",
    "    ])\n",
    "    norm = Normalize(vmin=0, vmax=9)\n",
    "    figure, axes = plt.subplots(2, n_examples, figsize=(n_examples * 4, 8))\n",
    "    for column, example in enumerate(examples):\n",
    "        axes[0, column].imshow(example['input'], cmap=cmap, norm=norm)\n",
    "        axes[1, column].imshow(example['output'], cmap=cmap, norm=norm)\n",
    "        axes[0, column].axis('off')\n",
    "        axes[1, column].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "tasks_train = load_tasks('training')\n",
    "tasks_test = load_tasks('evaluation')\n",
    "plot_task(tasks_train['0a938d79'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from _search import search, seq_to_program, i2p\n",
    "from arc.arc_search._search import search, i2p\n",
    "import arc.arc_dsl.dsl as dsl\n",
    "\n",
    "MAX_LENGTH = 40\n",
    "\n",
    "DSL_primitives = get_functions(dsl)\n",
    "itop = [p.__name__ for p in DSL_primitives]\n",
    "ptoi = {p: i for i, p in enumerate(itop)}\n",
    "\n",
    "i_identity = ptoi['identity']\n",
    "\n",
    "i2p = partial(i2p, itop=itop)\n",
    "i2p = np.vectorize(i2p)\n",
    "\n",
    "primitive_names = {p.__name__ for p in DSL_primitives}\n",
    "print(f\"DSL consists of {len(DSL_primitives)} primitives: {primitive_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primitive_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:52:01.973064Z",
     "iopub.status.busy": "2024-06-12T22:52:01.972518Z",
     "iopub.status.idle": "2024-06-12T22:52:02.031027Z",
     "shell.execute_reply": "2024-06-12T22:52:02.029219Z",
     "shell.execute_reply.started": "2024-06-12T22:52:01.973025Z"
    },
    "id": "blnTxyvByumr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# the maximum composition depth to consider\n",
    "MAX_DEPTH = 2\n",
    "\n",
    "# construct the program strings of all programs expressible by composing at most MAX_DEPTH primitives\n",
    "program_strings = search(MAX_DEPTH, primitive_names)\n",
    "# print some of the program strings\n",
    "print('\\n'.join([*program_strings[:10], '...']))\n",
    "print(f'Space to search consists of {len(program_strings)} programs:\\n')\n",
    "\n",
    "# map program strings to programs\n",
    "programs = {prog_str: eval(prog_str) for prog_str in program_strings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:50:20.776661Z",
     "iopub.status.busy": "2024-06-12T22:50:20.776108Z",
     "iopub.status.idle": "2024-06-12T22:50:49.308717Z",
     "shell.execute_reply": "2024-06-12T22:50:49.307578Z",
     "shell.execute_reply.started": "2024-06-12T22:50:20.776609Z"
    },
    "id": "MgebDnPgyumr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# TODO: How do I paralellize this\n",
    "def solve(tasks, programs):\n",
    "    guesses = dict()\n",
    "    for (key, task) in tqdm.tqdm(tasks.items()):\n",
    "        train_inputs = [example['input'] for example in task['train']]\n",
    "        train_outputs = [example['output'] for example in task['train']]\n",
    "        hypotheses = []\n",
    "        # iterate over all programs\n",
    "        if isinstance(programs, dict):\n",
    "            programs = programs.items()\n",
    "        for program_string, program in programs:\n",
    "            try:\n",
    "                if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n",
    "                    # remember program if it explains all training examples\n",
    "                    hypotheses.append(program_string)\n",
    "            except:\n",
    "                pass\n",
    "        # select first program for making predictions\n",
    "        if len(hypotheses) > 0:\n",
    "            print(f'found {len(hypotheses)} candidate programs for task {key}!')\n",
    "            guesses[key] = hypotheses[0]\n",
    "    print(f'\\nMade guesses for {len(guesses)} tasks')\n",
    "    return guesses\n",
    "\n",
    "guesses = solve(tasks_train, programs)\n",
    "guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:52:26.925245Z",
     "iopub.status.busy": "2024-06-12T22:52:26.924798Z",
     "iopub.status.idle": "2024-06-12T22:52:26.952322Z",
     "shell.execute_reply": "2024-06-12T22:52:26.950573Z",
     "shell.execute_reply.started": "2024-06-12T22:52:26.92521Z"
    },
    "id": "apRGd_Rgyumr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# make predictions and evaluate them\n",
    "\n",
    "solved = dict()\n",
    "\n",
    "# iterate over all tasks for which a guess exists\n",
    "for key, program_string in guesses.items():\n",
    "    # test_inputs = [example['input'] for example in train_challenges[key]['test']]\n",
    "    test_inputs = [example['input'] for example in tasks_train[key]['test']]\n",
    "    test_outputs = [example['output'] for example in tasks_train[key]['test']]\n",
    "    program = eval(program_string)\n",
    "    if all([program(i) == o for (i, o) in zip(test_inputs, test_outputs)]):\n",
    "    # if all([program(i) == o for i, o in zip(test_inputs, train_solutions[key])]):\n",
    "        # mark predition as correct if all test examples are solved by the program\n",
    "        solved[key] = program_string\n",
    "\n",
    "\n",
    "print(f'Predictions correct for {len(solved)}/{len(guesses)} tasks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:52:29.492151Z",
     "iopub.status.busy": "2024-06-12T22:52:29.491705Z",
     "iopub.status.idle": "2024-06-12T22:52:31.025246Z",
     "shell.execute_reply": "2024-06-12T22:52:31.022639Z",
     "shell.execute_reply.started": "2024-06-12T22:52:29.492116Z"
    },
    "id": "AQLRwaDoyumr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# visualize solved tasks\n",
    "for key, program_string in solved.items():\n",
    "    print(f'For task \"{key}\", found program \"{program_string}\"')\n",
    "    plot_task(tasks_train[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_vApiQGyumr"
   },
   "source": [
    "While this code runs extremely fast (considering 400 tasks in less than 10 seconds), it also performs extremely poor (solving only 4/400 tasks, giving a mere 1% accuracy). How could it be improved? What can be learned from it? There are at least two issues with the above approach to searching a space of programs expressible in a DSL: First, the DSL provided here is not very expressive in that for most tasks, no program that solves it exists in the set of all possible programs buildable in the DSL. Second, even if sufficient expressivity is guaranteed (e.g. via a turing-complete DSL), for which by definition there would exist solution programs to each task, such programs may in practice either not be discoverable in the first place or not detectable as correct programs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM1-HtYuyumr"
   },
   "source": [
    "### Increasing DSL Expressivity\n",
    "It is obvious why some tasks can't be solved by the above DSL, but one simple proof would be the following: No primitive ever increases the pixel count of a grid, hence neither can any composition of the primitives ever do so - and since for certain tasks, the output grids do have more pixels than the input grids, the DSL is incomplete. To increase the expressibity of the program space (disregarding the maximum program size), one will want to expand the set of the primitives and also extend the structure of the considered programs beyond mere composition. Maybe it is a good idea to have primitives which take more than one input argument, or primitives that operate on types other than only grids, such as objects or integers. Note that viewing the transformations from inputs to outputs as a linear function composition is very misleading, as many tasks can't be neatly squeezed into this form: Some tasks seem much better addressed on a pixel- or object-level than on a grid-level. A good DSL is probably concise and allows expressing solutions to many tasks as short programs. Such a DSL may best be built by bootstrapping, that is, building a minimal version of it and then iterating back and forth between using it to solve ARC tasks and expanding it to account for unsolvable ARC tasks, all while having abstractness and flexibility of the primitives and how they can interplay in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:52:43.183158Z",
     "iopub.status.busy": "2024-06-12T22:52:43.182488Z",
     "iopub.status.idle": "2024-06-12T22:52:43.57479Z",
     "shell.execute_reply": "2024-06-12T22:52:43.572911Z",
     "shell.execute_reply.started": "2024-06-12T22:52:43.183107Z"
    },
    "id": "7MrlEe_xyums",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# example of task where above DSL is ill-suited and e.g. an object-centric view could be more appropriate.\n",
    "# Potentially useful primitives: object extraction, property detection (has 6 pixels) and transformations (recolor)\n",
    "plot_task(tasks_train['b775ac94'])\n",
    "# this guy needs a much simpler dsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:52:49.399975Z",
     "iopub.status.busy": "2024-06-12T22:52:49.399408Z",
     "iopub.status.idle": "2024-06-12T22:52:49.751495Z",
     "shell.execute_reply": "2024-06-12T22:52:49.749502Z",
     "shell.execute_reply.started": "2024-06-12T22:52:49.399924Z"
    },
    "id": "7F5cLumWyums",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# example of task where above DSL is ill-suited and e.g. a more pixel-centric view could be more appropriate.\n",
    "# Potentially useful: cellular automata\n",
    "plot_task(tasks_train['3906de3d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4drRJahyums"
   },
   "source": [
    "### Increasing Search Efficiency\n",
    "To increase the efficiency of the search for programs, it is crucial to avoid a brute force search, as it very quickly becomes entirely infeasible as the size of the programs and the number of primitives grow: Even for a simplistic DSL where the primitives can only interact with each other via composition, if it consists of p primitives and one wants to check all programs up to depth d, the number of programs to consider with grow on the order of $p^d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2IiZoEPhyums"
   },
   "source": [
    "Naively, \"pruning the search space\" or avoiding considering primitives or subprograms unlikely useful for a solution program could be addressed by building heuristics into the search, e.g. \"whenever the output grid is always of the same size as the input grid for all training examples, don't consider grid rescaling operations during the search\". However, not only would such an approach be extremely labour-intensive, but also likely prone to result in a brittle and static system that would performs poorly. Maybe the navigation of the search space is something that can or even should be learned, not hardcoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T22:53:01.092855Z",
     "iopub.status.busy": "2024-06-12T22:53:01.092374Z",
     "iopub.status.idle": "2024-06-12T22:53:01.119805Z",
     "shell.execute_reply": "2024-06-12T22:53:01.118188Z",
     "shell.execute_reply.started": "2024-06-12T22:53:01.092818Z"
    },
    "id": "6PBuhrjJyums",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# some calculations on infeasibility of brute force search\n",
    "pd_arr = [(p, d) for p in [8, 16, 32] for d in [2, 4, 8]]\n",
    "for p, d in sorted(pd_arr, key=lambda pd: pd[0]**pd[1]):\n",
    "    print(f'DSL with {p} primitives and max. depth {d} allows > {p**d} programs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAsMkM85yums"
   },
   "source": [
    "### Outlook\n",
    "\n",
    "Creating your own DSL from scratch will probably not be easy and may not be desired or needed in the first place. There are at least two open-source DSLs for ARC, for example [Johan's DSL](https://github.com/top-quarks/ARC-solution) which he also used to win the first ARC-competition in 2020 with 20.6% by having efficient implementations and simple primitive signatures rendering a large-scale search feasible. Alternatively, I have built a separate, less minimal [ARC-DSL](https://github.com/michaelhodel/arc-dsl) that comes alongside reference [solution programs for all 400 ARC training tasks](https://github.com/michaelhodel/arc-dsl/blob/main/solvers.py) and which was also used for more recent program synthesis approaches such as [CodeIt](https://arxiv.org/pdf/2402.04858) that may be useful, even if just as inspiration. However, not following other's footsteps can also have benefits, such as not having to work with something that may be suboptimal for the desired approach at hand and by that getting stuck in a local minimum, and maybe a more adequate DSL for ARC is yet to be created, maybe by you!\n",
    "\n",
    "And, of course, using a DSL and searching over it is by no means the only way or all there is to ARC. Arguably, much work is yet to be done, and novelty and diversity in approaches seem in dire need to make progress on the benchmark, and with that hopefully ultimaltely towards much more advanced AI.\n",
    "\n",
    "Happy ARC-ing and good luck with the ARC-prize!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-12T23:00:50.433078Z",
     "iopub.status.busy": "2024-06-12T23:00:50.432445Z",
     "iopub.status.idle": "2024-06-12T23:00:59.303197Z",
     "shell.execute_reply": "2024-06-12T23:00:59.300973Z",
     "shell.execute_reply.started": "2024-06-12T23:00:50.433029Z"
    },
    "id": "9I_ox7kNyums",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# let's try to make a submission\n",
    "\n",
    "submission = dict()\n",
    "# iterate over all tasks\n",
    "for key, task in tqdm.tqdm(tasks_train.items()):\n",
    "    train_inputs = [example['input'] for example in task['train']]\n",
    "    train_outputs = [example['output'] for example in task['train']]\n",
    "    hypotheses = []\n",
    "    # iterate over all programs\n",
    "    for program_string, program in programs.items():\n",
    "        try:\n",
    "            if all([program(i) == o for i, o in zip(train_inputs, train_outputs)]):\n",
    "                # remember program if it explains all training examples\n",
    "                hypotheses.append(program_string)\n",
    "        except:\n",
    "            pass\n",
    "    # select first program for making predictions\n",
    "    predictions = [example['input'] for example in task['test']]\n",
    "    if len(hypotheses) > 0:\n",
    "        print(f'found {len(hypotheses)} candidate programs for task {key}!')\n",
    "        program_string = hypotheses[0]\n",
    "        program = eval(program_string)\n",
    "        try:\n",
    "            predictions = [program(example['input']) for example in task['test']]\n",
    "        except:\n",
    "            pass\n",
    "    submission[key] = [{'attempt_1': grid, 'attempt_2': grid} for grid in predictions]\n",
    "print(f'\\nMade guesses for {len(guesses)} tasks')\n",
    "\n",
    "with open('submission.json', 'w') as fp:\n",
    "    json.dump(submission, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arc.arc_search._mcts import *\n",
    "\n",
    "visits(make_node(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lambda I: ayo(world(hello(I)))'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_program_string(('hello', 'world', 'ayo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hello', 'world')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "('hello',) + ('world',)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Program Synthesis Starter Notebook",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8810484,
     "sourceId": 67357,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
